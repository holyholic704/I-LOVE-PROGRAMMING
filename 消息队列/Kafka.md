# Kafka

Kafka 是一个开源的分布式事件流处理平台，可以实时发布、订阅、存储和处理事件流，由 Scala 和 Java 编写。主要有 3 个关键功能

1. 发布（写入）和订阅（读取）事件流，包括从其他系统持续导入或导出数据
2. 根据需要持久可靠地存储事件流
3. 实时处理事件流

主要有 2 种应用场景：消息队列、数据处理

## 核心概念

![](./md.assets/kafka.png)

<small>[Kafka 设计原理 - Kafka架构](https://cloud.tencent.com/developer/article/1005736)</small>

### broker（代理）

Kafka 的服务节点，即 Kafka 服务器

### producer（生产者）

负责生产消息

### consumer（消费者）

负责消费消息

### topic（主题）

主题是一个逻辑上的概念，Kafka 中的消息以主题为单位进行划分

生产者将消息发送到特定的主题，消费者通过订阅特定的主题获得消息并消费

### consumer group（消费者组）

每个消费者都属于一个特定的消费者组，一个消费者组可以包含一个或多个消费者

- 同一条消息可以被不同消费者组消费
- 在同一个消费者组中，一条消息只能由组内的某一个消费者进行消费

对于消息中间件而言，一般有两种消息投递模式：点对点（P2P）模式、发布 / 订阅（Pub / Sub）模式

- 如果所有的消费者在同一个消费组中，那么每条消息只会被其中一个消费者处理，相当于点对点模式
- 如果所有的消费者在不同的消费组中，那么每条消息会被所有的消费者处理，相当于发布 / 订阅模式

每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串

### partition（分区）

一个主题可以有一个或多个分区。并且同一个主题下的分区可以分布在不同的 broker 上

同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（log）文件，消息在被追加到分区日志、文件的时候都会分配一个特定的偏移量（offset）

分区以文件形式存储在文件系统，目录命名规则：`<topic_name>-<partition_id>`

#### 分区选择策略

生产者的分区分配是指为每条消息指定其所要发往的分区，消费者中的分区分配是指为消费者指定其可以消费消息的分区

##### 生产者分区选择策略

- 指定某个分区
- 没有指定的分区，但是存在 key，在发送消息时可以指定消息的 key，key 的作用是将将消息与特定的分区进行绑定，此时将 key 的 hash 值与该主题的分区总数进行取余
- 没有指定的分区，也不存在 key，在第一次调用时会随机生成一个整数，后面每次调用在这个整数上自增，将这个值与可用的分区总数取余

### offset（偏移量）

offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，每个分区都有自己独立的 offset

offset 从 0 开始，每当有新的消息写入分区时，offset 就会加 1。offset 是不可变的，即使消息被删除或过期，offset 也不会改变或重用

![](./md.assets/offset.png)

<small>[Kafka Offset Explained](https://kontext.tech/diagram/1159/kafka-offset-explained)</small>

主要有 3 大作用

1. 消息的顺序：可以用于保证分区内的消息的顺序
2. 容错与恢复：消费者通过跟踪偏移量来实现容错和恢复，当消费者发生崩溃重启后，可以使用之前提交的偏移量来继续消费
3. 提交与控制：消费者可以手动提交偏移量，在重启时能够从上次提交的位置继续，这也是为了避免重复消费或消息丢失的情况

### replication（副本）

为了保证数据的高可用，每个分区以有多个副本，分布在不同的 broker 上

- leader：每个分区可以有多个副本，其中有且只有一个可以作为 leader，只有他负责对外提供读写服务
- follower：follower 跟随 leader，所有写请求都通过 leader 路由，数据变更会广播给所有 follower

分区使用多副本机制来提升可靠性，生产者和消费者只与 leader 副本进行交互，而 follower 副本只负责消息的同步，很多时候 follower 副本中的消息相对 leader 副本而言会有一定的滞后

如果一个分区的 leader 副本不可用，那么就意味着整个分区变得不可用，此时就需要 Kafka 从剩余的 follower 副本中挑选一个新的 leader 副本来继续对外提供服务

## 消息同步 ISR

分区中的所有副本统称为 AR (Assigned Replicas）。所有与 leader 保持一定程度同步的副本（包括 leader 副本在内）组成 ISR（In-Sync Replicas)。所有与 leader 滞后过多的副本组成 OSR（Out-of-Sync Replicas）

leader 负责维护和跟踪 ISR 集合中所有 follower 的滞后状态，follower 落后或失效时，leader 会把它从 ISR 集合中剔除。OSR 集合中有 follower 追上了 leader，那么 leader 会把它从 OSR 集合转移至 ISR 集合

当生产者将消息发送到 Kafka 的一个分区时，消息首先被写入 leader，然后 leader 会将消息同步到 ISR 中的其他副本。leader 在 ISR 中的副本都成功地接收并复制了消息之后，leader 才会向生产者发送确认，当然也有其他的一些确认策略

ISR 的存在有助于保障数据的可靠性和一致性。如果一个副本不能及时地跟上 leader 的写入，Kafka 会将其从 ISR 中移除，以确保只有跟上同步的副本才会参与消息的写入。这样可以有效地防止数据的不一致，同时提高系统的可用性

### ACK 设置

生产者的确认方式

- `acks=0`：生产者不等待确认，直接发送下一条消息
  - 这一操作提供了最低的延迟，如果 leader 还没完成写入，broker 发生故障有可能丢失数据
- `acks=1`：leader 在将消息写入本地日志后会向生产者发送确认
  - 如果在 follower 同步成功之前 leader 故障，那么将丢失数据。只有 leader 写入成功
- `acks=-1`（或 `acks=all`）：leader 在将消息写入本地日志并等待所有 ISR 副本确认后才向生产者发送确认
  - 如果在 follower 同步完成后，发送确认消息之前，leader 发生了故障，会造成数据重复。这里的数据重复是因为没有收到，所以继续重发导致的数据重复

### 重试

如果 leader 一直没有发送 ack，生产者会不断重试发送消息，直到达到配置的最大重试次数。一旦重试次数达到上限，生产者将放弃发送消息，并根据配置中的错误处理策略来处理

- 触发 Leader 重新选举：如果发生 Leader 选举，并且新的 Leader 已经被选举出来，生产者会尝试将消息发送到新的 Leader。这是因为 Leader 选举可能发生在 ISR（In-Sync Replicas）中的某个副本上。生产者会尝试将消息发送到新的 Leader，并等待确认。如果新的 Leader 成功接收并确认消息，那么整个过程就会继续。

生产者的配置中通常包含了一个retry.backoff.ms参数，用于指定在重试发送消息之前等待的时间。这个参数表示在两次重试之间等待的时间间隔，以毫秒为单位。这个时间间隔的设置可以帮助避免在网络瞬时故障或 Leader 选举等情况下过于频繁地重试发送消息

## Zookeeper

ZooKeeper 主要为 Kafka 提供元数据的管理的功能，协调 Kafka 的正常运行

- Broker 注册：每个 Broker 在启动时，都会到 Zookeeper 上进行注册并交由管理
- Topic 注册：在 Kafka 中，同一个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护
- 生产者负载均衡：一个 Topic 可以有多个 Partition，并分布在不同的 Broker 上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡

## 数据一致性

• **LEO(Log End Offset)**：每个副本最后的一个offset

• **HW(High Watermark)**：高水位，指代消费者能见到的最大的offset，ISR队列中最小的LEO。消费者只能拉取到这个offset之前的消息

### 分区故障

• Follower 分区故障：

• 当 Follower 发生故障时，它会被临时从 ISR 中提出。在恢复后，Follower 会读取本地磁盘记录的上次的 HW（High Watermark），并将 log 文件高于 HW 的部分截取掉。接着，Follower 从 HW 开始向 Leader 进行同步，等待 Follower 的 LEO（Log End Offset）大于等于该 Partition 的 HW。一旦 Follower 追上 Leader，它就可以重新加入 ISR。

• Leader 故障：

• 当 Leader 发生故障时，Kafka 会从 ISR 中选举出一个新的 Leader。为了保证多个副本之间的数据一致性，其余的 Follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 Leader 中同步数据。

## 消息传输

### At Most Once

• 特性： 这种语义保证消息最多被传递一次，但不保证一定被传递。

• 适用场景： 适用于对消息重复出现非常敏感，但对消息丢失的容忍度较高的场景。在这种语义下，如果消息在传递过程中丢失，可能不会被再次传递。

🌟 将服务器 ACK 级别设置为0，可以保证生产者每条消息只会被发送一次，但是不能保证数据不丢失。

### At Least Once

• 特性： 这种语义保证消息至少被传递一次，但允许重复。

• 适用场景： 适用于对消息重复出现不太敏感，但要求不丢失消息的场景。在消息系统中，可能会存在网络故障、生产者重试等情况，导致消息可能被传递多次。

🌟 将服务器的 ACK 级别设置为-1（all），可以保证 Producer 到 Server 之间不会丢失数据，但是不能保证数据不重复。

此时再思考最初提出的问题，当消费者实例与 Partition 绑定消费的时候，重复消费更多是因为 Partition 分区同步数据时，出现 rebalance 导致日志存储了多条相同消息。

### Exactly Once

• 特性： 这种语义既保证消息不丢失，又保证消息不重复，是最高级别的语义。

• 适用场景： 适用于对消息的完整性和一致性要求非常高的场景。在这种语义下，每条消息被确保只传递一次且不会重复。

在0.11版本的 Kafka 之前，只能保证数据不丢失，在下游对数据的重复进行去重操作，多余多个下游应用的情况，则分别进行全局去重，对性能有很大影响。

0.11版本的 Kafka，引入了一项重大特性：幂等性，幂等性指代 Producer 不论向 Server发送了多少次重复数据，Server 端都只会持久化一条数据。幂等性结合 At Least Once 语义就构成了 Kafka 的 Exactly Once 语义。

启用幂等性，即在 Producer 的参数中设置 enable.idempotence=true 即可，Kafka 的幂等性实现实际是将之前的去重操作放在了数据上游来做，开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一个 Partition 的消息会附带 Sequence Number ，而 Broker 端会对<PID,Partition,SeqNumber> 做缓存，当具有相同主键的消息的时候，Broker 只会持久化一条。

但 PID 在重启之后会发生变化，同时不同的 Partition 也具有不同的主键，所以幂等性无法保证跨分区跨会话的 Exactly Once。

## 存储

针对数据写入，Kafka 的设计充分发挥了内存和磁盘的优势，使 Kafka 在高吞吐量和数据持久性之间取得了良好的平衡。

• 性能优化：将消息首先追加到当前的活跃日志段（在内存中的磁盘页缓存中）可以提高写入性能，因为写入内存相对于直接写入磁盘来说是更快的操作。这使得 Kafka 能够更高效地处理大量的写入请求。

• 顺序写入：将消息追加到本地的活跃日志段通常是一个顺序写操作，而磁盘上的写操作是相对较慢的。通过先将消息追加到内存中的日志段，Kafka 可以最大程度上进行顺序写入，提高写入性能。

• 批量处理：Kafka 通常会以批量的方式处理消息，将一批消息一次性追加到磁盘日志中，这也有助于提高写入性能。

• 持久性：尽管消息首先被追加到内存中的日志段，但由于这些日志段最终会刷新到磁盘上，数据仍然是持久的。

## 消费消息不等于删除旧消息

即使不断消费消息，提交 offset，历史的 segment 文件仍然会被保留在磁盘上。这是因为 Kafka 的日志分段机制导致了历史数据的保留。老的 segment 文件不会被删除，而是保留在磁盘上，以便后续的查询和检索。

这也就促成了：多个消费者组可以独立消费同一个 Topic 的内容，但是同一个消费者组内只能有一个实例消费某一条消息的功能实现。

这个机制保证了 Kafka 的高吞吐量和持久性。但如果你希望限制 Kafka 的存储大小，你可能需要考虑定期清理旧的数据或者采用其他策略来管理磁盘空间。在实际生产环境中，通常会配置相应的参数和策略来控制日志的大小和保留时间。



Kafka之所以受到越来越多的青睐，与它所“扮演”的三大角色是分不开的：
· 消息系统：Kafka 和传统的消息系统（也称作消息中间件）都具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。与此同时，Kafka 还提供了大多数消息系统难以实现的消息顺序性保障及回溯消费的功能。
· 存储系统：Kafka 把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka 的消息持久化功能和多副本机制，我们可以把Kafka作为长期的数据存储系统来使用，只需要把对应的数据保留策略设置为“永久”或启用主题的日志压缩功能即可。
· 流式处理平台：Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作。

每一条消息被发送到broker之前，会根据分区规则选择存储到哪个具体的分区。如果分区规则设定得合理，所有的消息都可以均匀地分配到不同的分区中。如果一个主题只对应一个文件，那么这个文件所在的机器 I/O 将会成为这个主题的性能瓶颈，而分区解决了这个问题。在创建主题的时候可以通过指定的参数来设置分区的个数，当然也可以在主题创建完成之后去修改分区的数量，通过增加分区的数量可以实现水平扩展。

Kafka 为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当Kafka集群中某个broker失效时仍然能保证服务可用




优先级队列

延时队列：消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费

由于某些原因消息无法被正确地投递，为了确保消息不会被无故地丢弃，一般将其置于一个特殊角色的队列，这个队列一般称为死信队列。后续分析程序可以通过消费这个死信队列中的内容来分析当时遇到的异常情况，进而可以改善和优化系统。

与死信队列对应的还有一个“回退队列”的概念，如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认，进而发生回滚消息的操作之后，消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常处理提供的一种机制保障。实际情况下，回退队列的角色可以由死信队列和重试队列来扮演。

重试队列其实可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到broker中。与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大

消费模式：消费模式分为推（push）模式和拉（pull）模式。推模式是指由broker主动推送消息至消费端，实时性较好，不过需要一定的流控机制来确保broker推送过来的消息不会压垮消费端。而拉模式是指消费端主动向broker请求拉取（一般是定时或定量）消息，实时性较推模式差，但可以根据自身的处理能力控制拉取的消息量。

广播消费：消息一般有两种传递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。对点对点的模式而言，消息被消费以后，队列中不会再存储消息，所以消息消费者不可能消费已经被消费的消息。虽然队列可以支持多个消费者，但是一条消息只会被一个消费者消费。发布/订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。



消息堆积

消息过滤


## 参考

- [Kafka 消费者组](https://www.cnblogs.com/shix0909/p/16579572.html)
- [java——spring boot集成kafka——broker、主题、分区、副本——概念理解](https://blog.csdn.net/m0_61442607/article/details/129787919)
